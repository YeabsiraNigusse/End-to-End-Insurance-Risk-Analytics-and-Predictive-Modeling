{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Statistical Hypothesis Testing for Insurance Risk Analytics\n",
    "\n",
    "## Objective\n",
    "Statistically validate or reject key hypotheses about risk drivers to form the basis of our new segmentation strategy.\n",
    "\n",
    "## Hypotheses to Test\n",
    "1. **H₀**: There are no risk differences across provinces\n",
    "2. **H₀**: There are no risk differences between zip codes\n",
    "3. **H₀**: There are no significant margin (profit) differences between zip codes\n",
    "4. **H₀**: There are no significant risk differences between Women and Men\n",
    "\n",
    "## Metrics\n",
    "- **Risk**: Quantified by Claim Frequency and Claim Severity\n",
    "- **Claim Frequency**: Proportion of policies with at least one claim\n",
    "- **Claim Severity**: Average amount of a claim, given a claim occurred\n",
    "- **Margin**: TotalPremium - TotalClaims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_preprocessing import InsuranceDataProcessor\n",
    "from statistical_utils import StatisticalTester\n",
    "from hypothesis_testing import InsuranceHypothesisTester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the insurance data\n",
    "# Note: Using the same data from EDA notebook\n",
    "try:\n",
    "    df = pd.read_csv(\"../data/MachineLearningRating_v3.txt\", sep=\"|\", low_memory=False)\n",
    "    print(f\"Real data loaded successfully. Shape: {df.shape}\")\n",
    "    \n",
    "    # For large datasets, sample for faster processing\n",
    "    if len(df) > 50000:\n",
    "        print(f\"Large dataset detected ({len(df)} records). Sampling 50,000 records for analysis...\")\n",
    "        df = df.sample(n=50000, random_state=42)\n",
    "        print(f\"Sampled data shape: {df.shape}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found. Creating sample data for demonstration...\")\n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    \n",
    "    provinces = ['Gauteng', 'Western Cape', 'KwaZulu-Natal', 'Eastern Cape', \n",
    "                'Free State', 'Mpumalanga', 'Limpopo', 'North West', 'Northern Cape']\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'PolicyID': range(1, n_samples + 1),\n",
    "        'Province': np.random.choice(provinces, n_samples, \n",
    "                                   p=[0.25, 0.20, 0.15, 0.10, 0.08, 0.08, 0.06, 0.05, 0.03]),\n",
    "        'PostalCode': np.random.choice(range(1000, 9999), n_samples),\n",
    "        'Gender': np.random.choice(['Male', 'Female', 'Other'], n_samples, p=[0.48, 0.48, 0.04]),\n",
    "        'Age': np.random.normal(40, 15, n_samples).clip(18, 80),\n",
    "        'VehicleType': np.random.choice(['Sedan', 'SUV', 'Hatchback', 'Truck'], n_samples),\n",
    "    })\n",
    "    \n",
    "    # Create correlated premium and claims data with province effects\n",
    "    province_risk_multiplier = {\n",
    "        'Gauteng': 1.2, 'Western Cape': 0.9, 'KwaZulu-Natal': 1.1,\n",
    "        'Eastern Cape': 1.0, 'Free State': 0.8, 'Mpumalanga': 1.0,\n",
    "        'Limpopo': 0.9, 'North West': 0.95, 'Northern Cape': 0.85\n",
    "    }\n",
    "    \n",
    "    gender_risk_multiplier = {'Male': 1.05, 'Female': 0.98, 'Other': 1.0}\n",
    "    \n",
    "    base_premium = 100 + df['Age'] * 2 + np.random.exponential(50, n_samples)\n",
    "    df['risk_multiplier'] = df['Province'].map(province_risk_multiplier) * df['Gender'].map(gender_risk_multiplier)\n",
    "    df['TotalPremium'] = base_premium * df['risk_multiplier'] + np.random.normal(0, 20, n_samples)\n",
    "    df['TotalPremium'] = df['TotalPremium'].clip(10, None)\n",
    "    \n",
    "    claim_probability = 0.25 * df['risk_multiplier']\n",
    "    has_claim = np.random.binomial(1, claim_probability.clip(0, 1), n_samples)\n",
    "    claim_amounts = np.random.exponential(df['TotalPremium'] * 0.8, n_samples) * has_claim\n",
    "    df['TotalClaims'] = claim_amounts\n",
    "    \n",
    "    df = df.drop(['risk_multiplier'], axis=1)\n",
    "    print(f\"Sample data created. Shape: {df.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the hypothesis tester\n",
    "hypothesis_tester = InsuranceHypothesisTester(df=df, alpha=0.05)\n",
    "\n",
    "# Get summary statistics before testing\n",
    "print(\"Summary Statistics by Key Variables:\")\n",
    "summaries = hypothesis_tester.processor.get_summary_statistics()\n",
    "\n",
    "for key, summary in summaries.items():\n",
    "    print(f\"\\n{key.upper()} Summary:\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis for Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for analysis\n",
    "hypothesis_data = hypothesis_tester.processor.prepare_hypothesis_data()\n",
    "\n",
    "# Display data preparation results\n",
    "for key, data in hypothesis_data.items():\n",
    "    print(f\"{key}: {data.shape[0]} records\")\n",
    "    print(f\"  - Claim frequency: {data['HasClaim'].mean():.3f}\")\n",
    "    if 'ClaimSeverity' in data.columns:\n",
    "        severity_mean = data['ClaimSeverity'].mean()\n",
    "        print(f\"  - Average claim severity: {severity_mean:.2f}\")\n",
    "    print(f\"  - Average margin: {data['Margin'].mean():.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key metrics by grouping variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Province analysis\n",
    "province_data = hypothesis_data['provinces']\n",
    "province_summary = province_data.groupby('Province').agg({\n",
    "    'HasClaim': 'mean',\n",
    "    'Margin': 'mean',\n",
    "    'LossRatio': 'mean'\n",
    "})\n",
    "\n",
    "province_summary['HasClaim'].plot(kind='bar', ax=axes[0,0], title='Claim Frequency by Province')\n",
    "axes[0,0].set_ylabel('Claim Frequency')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "province_summary['Margin'].plot(kind='bar', ax=axes[0,1], title='Average Margin by Province')\n",
    "axes[0,1].set_ylabel('Average Margin')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gender analysis\n",
    "gender_data = hypothesis_data['gender']\n",
    "gender_summary = gender_data.groupby('Gender').agg({\n",
    "    'HasClaim': 'mean',\n",
    "    'Margin': 'mean'\n",
    "})\n",
    "\n",
    "gender_summary['HasClaim'].plot(kind='bar', ax=axes[1,0], title='Claim Frequency by Gender')\n",
    "axes[1,0].set_ylabel('Claim Frequency')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "gender_summary['Margin'].plot(kind='bar', ax=axes[1,1], title='Average Margin by Gender')\n",
    "axes[1,1].set_ylabel('Average Margin')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all hypothesis tests\n",
    "print(\"Running comprehensive hypothesis testing...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = hypothesis_tester.run_all_hypothesis_tests()\n",
    "\n",
    "print(\"\\nHypothesis testing completed!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for each hypothesis\n",
    "hypothesis_names = {\n",
    "    'H1_provinces': 'H₁: Risk differences across provinces',\n",
    "    'H2_zip_codes': 'H₂: Risk differences between zip codes',\n",
    "    'H3_zip_margin': 'H₃: Margin differences between zip codes',\n",
    "    'H4_gender': 'H₄: Risk differences between genders'\n",
    "}\n",
    "\n",
    "for hypothesis_key, hypothesis_name in hypothesis_names.items():\n",
    "    if hypothesis_key in results:\n",
    "        result = results[hypothesis_key]\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{hypothesis_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Null Hypothesis: {result.get('hypothesis', 'N/A')}\")\n",
    "        \n",
    "        # Display test results\n",
    "        if 'tests' in result:\n",
    "            for test_name, test_result in result['tests'].items():\n",
    "                print(f\"\\n{test_name.upper()} TEST:\")\n",
    "                print(f\"  Test: {test_result.get('test_name', 'N/A')}\")\n",
    "                print(f\"  Statistic: {test_result.get('statistic', 'N/A'):.4f}\")\n",
    "                print(f\"  P-value: {test_result.get('p_value', 'N/A'):.6f}\")\n",
    "                print(f\"  Significant: {test_result.get('significant', 'N/A')}\")\n",
    "                print(f\"  Interpretation: {test_result.get('interpretation', 'N/A')}\")\n",
    "        \n",
    "        # Display conclusion\n",
    "        if 'conclusion' in result:\n",
    "            conclusion = result['conclusion']\n",
    "            print(f\"\\nCONCLUSION:\")\n",
    "            print(f\"  Decision: {conclusion.get('decision', 'N/A')}\")\n",
    "            print(f\"  Evidence: {conclusion.get('evidence', 'N/A')}\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Report and Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive summary\n",
    "if 'summary' in results:\n",
    "    summary = results['summary']\n",
    "    \n",
    "    print(\"COMPREHENSIVE HYPOTHESIS TESTING SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"Total hypotheses tested: {summary.get('total_hypotheses_tested', 0)}\")\n",
    "    \n",
    "    print(f\"\\nREJECTED HYPOTHESES ({len(summary.get('rejected_hypotheses', []))}):\"))\n",
    "    for rejected in summary.get('rejected_hypotheses', []):\n",
    "        print(f\"  • {rejected.get('hypothesis', 'N/A')}\")\n",
    "        print(f\"    Evidence: {rejected.get('evidence', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nFAILED TO REJECT HYPOTHESES ({len(summary.get('failed_to_reject_hypotheses', []))}):\"))\n",
    "    for not_rejected in summary.get('failed_to_reject_hypotheses', []):\n",
    "        print(f\"  • {not_rejected.get('hypothesis', 'N/A')}\")\n",
    "        print(f\"    Evidence: {not_rejected.get('evidence', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nBUSINESS RECOMMENDATIONS:\")\n",
    "    for i, recommendation in enumerate(summary.get('business_recommendations', []), 1):\n",
    "        print(f\"  {i}. {recommendation}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Statistical Results Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed results DataFrame for export\n",
    "detailed_results = []\n",
    "\n",
    "for hypothesis_key, hypothesis_name in hypothesis_names.items():\n",
    "    if hypothesis_key in results:\n",
    "        result = results[hypothesis_key]\n",
    "        \n",
    "        if 'tests' in result:\n",
    "            for test_name, test_result in result['tests'].items():\n",
    "                detailed_results.append({\n",
    "                    'Hypothesis': hypothesis_name,\n",
    "                    'Test_Type': test_name,\n",
    "                    'Statistical_Test': test_result.get('test_name', 'N/A'),\n",
    "                    'Statistic': test_result.get('statistic', np.nan),\n",
    "                    'P_Value': test_result.get('p_value', np.nan),\n",
    "                    'Effect_Size': test_result.get('effect_size', np.nan),\n",
    "                    'Significant': test_result.get('significant', False),\n",
    "                    'Decision': result.get('conclusion', {}).get('decision', 'N/A')\n",
    "                })\n",
    "\n",
    "results_df = pd.DataFrame(detailed_results)\n",
    "print(\"Detailed Statistical Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('../results/hypothesis_testing_results.csv', index=False)\n",
    "print(\"\\nResults saved to '../results/hypothesis_testing_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
